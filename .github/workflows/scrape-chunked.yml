# File: .github/workflows/scrape-chunked.yml
name: Chunked RKGuns Scrape

on:
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        range: ["1-70","71-140","141-210","211-278"]  # four chunks

    env:
      PAGES: ${{ matrix.range }}

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Parse START/END pages
        run: |
          IFS="-" read START END <<< "${PAGES}"
          echo "START_PAGE=$START" >> $GITHUB_ENV
          echo "END_PAGE=$END"   >> $GITHUB_ENV

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          sudo apt-get update && sudo apt-get install -y chromium-browser chromium-chromedriver

      - name: Run chunked scraper
        run: python scraper_selenium_chunked.py

      - name: Upload chunk CSV
        uses: actions/upload-artifact@v4
        with:
          name: inventory_${{ env.START_PAGE }}_${{ env.END_PAGE }}.csv
          path: inventory_${{ env.START_PAGE }}_${{ env.END_PAGE }}.csv

  merge:
    needs: scrape
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Download all chunk artifacts
        uses: actions/download-artifact@v3
        with:
          name: |
            inventory_1_70.csv,
            inventory_71_140.csv,
            inventory_141_210.csv,
            inventory_211_278.csv
          path: .

      - name: Merge into inventory.csv
        run: |
          head -n1 inventory_1_70.csv > inventory.csv
          tail -n+2 -q inventory_*.csv >> inventory.csv

      - name: Upload final CSV
        uses: actions/upload-artifact@v4
        with:
          name: inventory.csv
          path: inventory.csv
